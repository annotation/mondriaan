{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1686644-c456-48d3-b771-9cda5fa1bd4d",
   "metadata": {},
   "source": [
    "# WATM\n",
    "\n",
    "We make an export of the Mondriaan letters to WATM, the suite of systems developed by Team Text for\n",
    "serving text plus annotations over the web.\n",
    "\n",
    "WATM = Web Annotation Model for Text and consists (currently) of TextRepo, AnnoRepo, Broccoli, and TextAnnoViz.\n",
    "\n",
    "The input data is given by a Text-Fabric dataset, which is in turn derived from TEI files managed by the\n",
    "Huygens institute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2828e-db4c-4548-903a-acd6b7e38f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate plain text\n",
    "\n",
    "We generate a plain text of the whole corpus.\n",
    "This will produce a text and annotation file:\n",
    "\n",
    "* `text.json`: with the text segments in an array;\n",
    "* `anno.json`: all generated annotations\n",
    "\n",
    "## Format of the text file\n",
    "\n",
    "A json file with the following structure:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"_ordered_segments\": [\n",
    "    \"word1 \",\n",
    "    \"word2 \",\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "* each item in `_ordered_segments` corresponds to one word,\n",
    "* the item contains the text of the word plus the subsequent interword material;\n",
    "* we skip all material inside the TEI-header;\n",
    "\n",
    "## Format of the annotation file\n",
    "\n",
    "A json file with the following structure:\n",
    "\n",
    "```\n",
    "{\n",
    " \"a000nnn\": [\n",
    "  \"kind\",\n",
    "  \"namespace\",\n",
    "  \"body\",\n",
    "  \"bbb-eee\"\n",
    " ],{\n",
    " ...\n",
    "}\n",
    "```\n",
    "* it is a big dict, keyed by annotation ids\n",
    "* the values consist of the annotation data, divided in the following fields:\n",
    "\n",
    "* `kind`: the kind of annotation\n",
    "  * `element`: targets the text location where an element occurs, the body is the element name;\n",
    "  * `attribute`: targets an element attribute, the body has the shape `*name*`=`*value*,\n",
    "    the name and value of the attribute in question;\n",
    "  * `node`: targets an individual words or elements, the body is the TF node of that word, or element;\n",
    "  * `edge`: targets two node annotations, the body has the shape\n",
    "    `*name* or `*name*`=`*value*,\n",
    "    where *name* is the name of the edge and *value* is the label of the edge if the edge has a label;\n",
    "  * `format`: targets an individual word, the body is a formatting property for that word,\n",
    "    all words in notes get a `format` annotation with body `note`;\n",
    "  * `anno`: targets an arbitrary annotation or text range, body has an arbitrary value;\n",
    "    can be used for extra annotations, e.g. the url to an artwork derived from an `<rs>` element.\n",
    "    \n",
    "* `namespace`: the namespace of the annotation; an indicator where the information comes from. Possible values:\n",
    "  * `tei`: attribute comes\n",
    "    [literally](https://annotation.github.io/text-fabric/tf/convert/helpers.html#tf.convert.helpers.CM_LIT)\n",
    "    from the TEI, or is\n",
    "    [processed](https://annotation.github.io/text-fabric/tf/convert/helpers.html#tf.convert.helpers.CM_LITP)\n",
    "    straightforwardly from it;\n",
    "  * `tf`: attribute is\n",
    "    [composed](https://annotation.github.io/text-fabric/tf/convert/helpers.html#tf.convert.helpers.CM_LITC)\n",
    "    in a more intricate way from the TEI or even\n",
    "    [added](https://annotation.github.io/text-fabric/tf/convert/helpers.html#tf.convert.helpers.CM_PROV)\n",
    "    to it;\n",
    "  * `nlp`: attribute is generated as a result of\n",
    "    [NLP processing](https://annotation.github.io/text-fabric/tf/convert/helpers.html#tf.convert.helpers.CM_NLP);\n",
    "  * `tt`: attribute is derived from other material in the TEI source for the benefit\n",
    "    of the Team Text infrastructure. Defined in the `watm.yaml` file next to this program.\n",
    "      \n",
    "* `body`: the body of an annotation (probably the *kind* and *body* fields together will make up the body\n",
    "  of the resulting web annotation);\n",
    "  \n",
    "* `target`: a string, of the following kinds:\n",
    "\n",
    "  * **single** this is a target pointing to a single thing, either:\n",
    "  \n",
    "    * `bbb-eee` a range of text segments in the `_ordered_segments`;\n",
    "    * an annotation id\n",
    "    \n",
    "  * **double** this is a target pointing to two things:\n",
    "    * `fff->ttt` where `fff` is a \"from\" target and `ttt` is a \"to\" target;\n",
    "      both targets can vary independently between a range and an annotation id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee380d-55e6-40fa-ac24-68bd2a63e600",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f70e87-d34b-4f14-b811-57eb150c1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e833f-f436-4c08-ae55-4aa1935f7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from tf.app import use\n",
    "from watm import WATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9462c-b36e-43c6-85f4-3a7b6f9a1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use(\"annotation/mondriaan/:clone\", checkout=\"clone\", hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021bbe6-8606-4e2e-ae94-cc69482791eb",
   "metadata": {},
   "source": [
    "We want to create special annotations for urls to artwork on the RKD site.\n",
    "\n",
    "We collect a mapping from TF nodes to such urls in order to pass that to the function that generates\n",
    "annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866116f-6bf2-4a4b-a445-6f8307a7a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipMeta = False\n",
    "WA = WATM(A, skipMeta=skipMeta)\n",
    "WA.makeText()\n",
    "WA.makeAnno()\n",
    "WA.writeAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb54200-55a7-4041-802c-6fd99cc91bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test\n",
    "\n",
    "Let's do a cross-check on our number manipulation.\n",
    "\n",
    "First we define a few compare functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df90d22-86e6-4816-9548-f4408bedd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(nTF, nWA):\n",
    "    print(f\"TF: {nTF:>6}\\nWA: {nWA:>6}\")\n",
    "    return nTF == nWA\n",
    "\n",
    "\n",
    "def strEqual(wa=None, tf=None):\n",
    "    different = False\n",
    "    for (i, cTF) in enumerate(tf):\n",
    "        if i >= len(wa):\n",
    "            contextI = max((0, i - 10))\n",
    "            print(f\"WA {i}: {wa[contextI:i]} <END>\")\n",
    "            print(f\"TF {i}: {tf[contextI:i]} <> {tf[i:i + 10]}\")\n",
    "            different = True\n",
    "            break\n",
    "        elif tf[i] != wa[i]:\n",
    "            contextI = max((0, i - 10))\n",
    "            print(f\"WA {i}: {wa[contextI:i]} <{wa[i]}> {wa[i+1:i + 11]}\")\n",
    "            print(f\"TF {i}: {tf[contextI:i]} <{tf[i]}> {tf[i+1:i + 11]}\")\n",
    "            different = True\n",
    "            break\n",
    "    if not different and len(wa) > len(tf):\n",
    "        i = len(tf)\n",
    "        contextI = max((0, i - 10))\n",
    "        print(f\"WA {i}: {wa[contextI:i]} <> {wa[i:i + 10]}\")\n",
    "        print(f\"TF {i}: {tf[contextI:i]} <END>\")\n",
    "        different = True\n",
    "    return not different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffbf73-b6d1-4c03-98b2-43d08761e796",
   "metadata": {},
   "source": [
    "We read the text and annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94523ea-f077-4777-9529-5a4e42e7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WA.textFile) as fh:\n",
    "    text = json.load(fh)\n",
    "    tokens = text[\"_ordered_segments\"]\n",
    "\n",
    "with open(WA.annoFile) as fh:\n",
    "    annotationById = {}\n",
    "    annotations = []\n",
    "    annos = json.load(fh)\n",
    "    \n",
    "    for (aId, (kind, ns, body, target)) in annos.items():\n",
    "        if \"->\" in target:\n",
    "            parts = target.split(\"->\", 1)\n",
    "        else:\n",
    "            parts = [target]\n",
    "        newParts = []\n",
    "        for part in parts:\n",
    "            if \"-\" in part:\n",
    "                (start, end) = part.split(\"-\", 1)\n",
    "                part = (int(start), int(end))\n",
    "            newParts.append(part)\n",
    "            \n",
    "        target = newParts[0] if len(newParts) == 1 else tuple(newParts)\n",
    "            \n",
    "        annotationById[aId] = (kind, body, target)\n",
    "        annotations.append((aId, kind, body, target))\n",
    "        \n",
    "    annotations = sorted(annotations)\n",
    "    \n",
    "if False:\n",
    "    with open(f\"{WA.annoFile}.txt\", \"w\") as fh:\n",
    "        for anno in annotations:\n",
    "            fh.write(f\"{anno=}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414da899-1f32-4173-8d06-2945a75a427d",
   "metadata": {},
   "source": [
    "## Does the number of tokens match?\n",
    "\n",
    "We compare the number of tokens in the textFile with the non-meta slots in the TF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37790cfe-fc4e-4ffd-ae28-ee0f7a7ffa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTokensTF = sum(0 if skipMeta and F.is_meta.v(s) else 1 for s in range(1, F.otype.maxSlot + 1))\n",
    "nTokensWA = len(tokens)\n",
    "compare(nTokensTF, nTokensWA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6650b05-24d3-4c5b-893d-b13608af7009",
   "metadata": {},
   "source": [
    "## Do both representations have the same text?\n",
    "\n",
    "We extract the from the text file and from TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0e195-d3b2-4c6d-8211-d06f5c2fcdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textWA = \"\".join(tokens)\n",
    "print(textWA[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49a066-a110-45a4-ab44-fa400f554760",
   "metadata": {},
   "outputs": [],
   "source": [
    "textTF = \"\".join(\n",
    "    f\"{F.str.v(s)}{F.after.v(s) or ''}\"\n",
    "    for s in F.otype.s(\"token\")\n",
    "    if not ((skipMeta and F.is_meta.v(s)) or F.empty.v(s))\n",
    ")\n",
    "print(textTF[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c74d3b-db8d-4f66-a830-21b336ea02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "strEqual(wa=textWA, tf=textTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff495d-4522-4940-b506-ecbc8ce46ce2",
   "metadata": {},
   "source": [
    "Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73add1b3-b63a-4a2d-bafb-3e3f60a9e970",
   "metadata": {},
   "source": [
    "## Does the number of element nodes match?\n",
    "\n",
    "We compare the number of element annotations in the file with the non-meta elements in the TF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20a763-0569-4fee-a819-e5e64d3a13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nElementsTF = 0\n",
    "\n",
    "for n in range(F.otype.maxSlot + 1, F.otype.maxNode + 1):\n",
    "    slots = E.oslots.s(n)\n",
    "    b = slots[0]\n",
    "    e = slots[-1]\n",
    "    if skipMeta and (F.is_meta.v(b) or F.is_meta.v(e)):\n",
    "        continue\n",
    "    nElementsTF +=1\n",
    "    \n",
    "nElementsWA = sum(1 if kind == \"element\" else 0 for (aId, kind, body, target) in annotations)\n",
    "compare(nElementsTF, nElementsWA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02336759-a9ca-4248-8f87-92c45f399d77",
   "metadata": {},
   "source": [
    "## Can we map the element annotations back to TF?\n",
    "\n",
    "We make a mapping from annotation ids of element annotations to TF nodes.\n",
    "\n",
    "Then for each element annotation, we check whether the body of the annotation contains the \n",
    "type of the corresponding TF node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62074f0-5765-42a5-8715-9ee6faa9a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfFromAid = {}\n",
    "\n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"node\":\n",
    "        continue\n",
    "    tfFromAid[target] = body\n",
    "        \n",
    "print(f\"Annotations mapped: {len(tfFromAid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a53ea8-be6e-4d16-be3d-03ba21773bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = 0\n",
    "other = 0\n",
    "good = 0\n",
    "wrong = 0\n",
    "unmapped = 0\n",
    "\n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"element\":\n",
    "        other += 1\n",
    "        continue\n",
    "    element += 1\n",
    "    tag = body\n",
    "    node = tfFromAid.get(aId, None)\n",
    "    if node is None:\n",
    "        unmapped += 1\n",
    "        continue\n",
    "    otype = F.otype.v(node)\n",
    "    if tag == otype:\n",
    "        good +=1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        \n",
    "print(f\"Element:  {element:>5} x\")\n",
    "print(f\"Other  :  {other:>5} x\")\n",
    "print(f\"Good:     {good:>5} x\")\n",
    "print(f\"Wrong:    {wrong:>5} x\")\n",
    "print(f\"Unmapped: {unmapped:>5} x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf8273-a4b6-436c-84cd-f131e46aa6b4",
   "metadata": {},
   "source": [
    "No errors or irregularities in the correspondence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36af65-8196-40de-82b7-c038bcab130a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Are the attributes preserved?\n",
    "\n",
    "Using the correspondence between element annotations and TF nodes, we test whether the\n",
    "annotations encode the same attributes and values as the TF does with its features.\n",
    "\n",
    "Note that in the generation of TF we may have added extra features, based on the elements and attributes.\n",
    "We also check, in one go, that these features have been transferred faithfully to\n",
    "corresponding annotations.\n",
    "\n",
    "We make a list of entries for all attribute values encoded in WATM.\n",
    "Each entry consists of:\n",
    "\n",
    "* node ID\n",
    "* attribute name\n",
    "* attribute value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0d0c5-57e1-4385-9769-f91f79d74fd1",
   "metadata": {},
   "source": [
    "First the WATM side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f75df1-3e7c-43c0-834a-ce9c643787ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "attWA = []\n",
    "\n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"attribute\":\n",
    "        continue\n",
    "    node = tfFromAid[target]\n",
    "    (att, value) = body.split(\"=\", 1)\n",
    "    attWA.append((node, att, value))\n",
    "    \n",
    "attWA = sorted(attWA)\n",
    "\n",
    "print(f\"{len(attWA)} attribute values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85273a5f-8309-4107-90d2-fe78ccc15741",
   "metadata": {},
   "source": [
    "Let's check whether this data is consistent with TF.\n",
    "\n",
    "Later we must also check that this data is complete, i.e. that it covers all feature data of TF.\n",
    "\n",
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497e7e9-13af-42df-a2fc-59922eebae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = 0\n",
    "wrong = []\n",
    "\n",
    "for (node, att, valWA) in attWA:\n",
    "    valTF = str(Fs(att).v(node))\n",
    "    if valWA == valTF:\n",
    "        good += 1\n",
    "    else:\n",
    "        wrong.append((node, att, valWA, valTF))\n",
    "        \n",
    "print(f\"Good:     {good:>5} x\")\n",
    "print(f\"Wrong:    {len(wrong):>5} x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ab059-300b-4586-9413-4918e4ab1405",
   "metadata": {},
   "source": [
    "### Completeness\n",
    "\n",
    "Are there features in TF not covered by WATM?\n",
    "\n",
    "We ignore the `rend_`, and `is_` features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b25523-16bd-4e4f-bf9e-45bc18ec087b",
   "metadata": {},
   "source": [
    "We collect the TF features in a list like `attWA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90868b-c6a3-49b5-bbcd-8bf11f0bf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attTF = []\n",
    "\n",
    "for feat in Fall():\n",
    "    if feat in {\"otype\", \"str\", \"after\"}:\n",
    "        continue\n",
    "        \n",
    "    if skipMeta and feat == \"is_meta\":\n",
    "        continue\n",
    "        \n",
    "    if (feat != \"is_meta\" and feat.startswith(\"is_\")) or feat.startswith(\"rend_\"):\n",
    "        continue\n",
    "    \n",
    "    for (node, valTF) in Fs(feat).items():\n",
    "        slots = E.oslots.s(node)\n",
    "        b = slots[0]\n",
    "        e = slots[-1]\n",
    "        if skipMeta and (F.is_meta.v(b) or F.is_meta.v(e)):\n",
    "            continue\n",
    "        attTF.append((node, feat, str(valTF)))\n",
    "\n",
    "attTF = sorted(attTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b50bc-b182-4757-9109-43097829d619",
   "metadata": {},
   "source": [
    "Now the big question is: are `attWA` and `attTF` the same data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd997ced-04c3-46a6-a3f8-99547a5f3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TL attributes: {len(attWA)}\")\n",
    "print(f\"TF attributes: {len(attTF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd5aa2-883c-40a3-b17b-d266896502d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attWA == attTF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5d27c-7148-4b0d-822c-3c718000e7ac",
   "metadata": {},
   "source": [
    "## Are the formatting attributes preserved?\n",
    "\n",
    "This is about the `rend` attributes in the TEI and the `format` annotations in the anno file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2526ce4-c103-4b41-a172-deca982cb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmtWA = []\n",
    "\n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"format\":\n",
    "        continue\n",
    "    if body == \"note\":\n",
    "        continue\n",
    "    node = tfFromAid[target]\n",
    "    fmtWA.append((node, body))\n",
    "    \n",
    "fmtWA = sorted(fmtWA)\n",
    "\n",
    "print(f\"{len(fmtWA)} format values\")\n",
    "{f[1] for f in fmtWA}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38089da1-c86b-4c01-959c-5ee2f4895db8",
   "metadata": {},
   "source": [
    "Let's check whether this data is consistent with TF.\n",
    "\n",
    "Later we must also check that this data is complete, i.e. that it covers all feature data of TF.\n",
    "\n",
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3493107-d0d7-44fe-8e7f-aa7059ad9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = 0\n",
    "wrong = []\n",
    "\n",
    "for (node, valWA) in fmtWA:\n",
    "    feat = f\"rend_{valWA}\"\n",
    "    valTF = valWA if str(Fs(feat).v(node)) else None\n",
    "    if valWA == valTF:\n",
    "        good += 1\n",
    "    else:\n",
    "        wrong.append((node, feat, valWA, valTF))\n",
    "        \n",
    "print(f\"Good:     {good:>5} x\")\n",
    "print(f\"Wrong:    {len(wrong):>5} x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164bb82-cfcc-49af-9467-645e39c76dbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Completeness\n",
    "\n",
    "Are there formats in TF not covered by WA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1867f-1650-4799-9c8b-ff6dd8113fcf",
   "metadata": {},
   "source": [
    "We collect the TF *rend* features in a list like `fmtWA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3272bd-116e-4495-bcd2-3c764aa85768",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmtTF = []\n",
    "\n",
    "for feat in Fall():\n",
    "    if not feat.startswith(\"rend_\"):\n",
    "        continue\n",
    "    \n",
    "    value = feat.split(\"_\", 2)[1]\n",
    "    if value == \"note\":\n",
    "        continue\n",
    "        \n",
    "    for (node, valTF) in Fs(feat).items():\n",
    "        slots = E.oslots.s(node)\n",
    "        b = slots[0]\n",
    "        e = slots[-1]\n",
    "        if skipMeta and (F.is_meta.v(b) or F.is_meta.v(e)):\n",
    "            continue\n",
    "        fmtTF.append((node, value))\n",
    "\n",
    "fmtTF = sorted(fmtTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f51909-436d-4860-ad7a-91aeed227c3c",
   "metadata": {},
   "source": [
    "Now the big question is: are `attWA` and `attTF` the same data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b89cc-4032-4c3f-83a1-5c06a8e9f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TL attributes: {len(fmtWA)}\")\n",
    "print(f\"TF attributes: {len(fmtTF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b8e5c-02ea-49e4-a106-ff4ab83d422d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fmtWA == fmtTF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc0faa-d8b0-4785-a305-11fb76c15810",
   "metadata": {},
   "source": [
    "## Are the edges preserved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4009e-0040-4c8b-82f2-2e2a2eaea168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"node\":\n",
    "        continue\n",
    "\n",
    "    if type(target) is not str:\n",
    "        print(f\"{aId=} {kind=} {body=} {target=}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fda8e2-7ca6-4abd-8bec-cebb88719b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfFromAidNodes = {}\n",
    "tfFromAidEdges = {}\n",
    "\n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"node\":\n",
    "        continue\n",
    "    if type(target) is tuple:\n",
    "        (start, end) = target\n",
    "        if start + 1 != end:\n",
    "            print(target)\n",
    "            break\n",
    "        target = end\n",
    "    tfFromAidNodes[target] = body\n",
    "        \n",
    "for (aId, kind, body, target) in annotations:\n",
    "    if kind != \"edge\":\n",
    "        continue\n",
    "        \n",
    "    (fro, to) = target\n",
    "    fromNode = tfFromAidNodes[fro]\n",
    "    toNode = tfFromAidNodes[to]\n",
    "    parts = body.split(\"=\", 1)\n",
    "    (name, val) = (body, None) if len(parts) == 1 else parts\n",
    "    tfFromAidEdges.setdefault(name, {}).setdefault(fromNode, {})[toNode] = val\n",
    "        \n",
    "print(f\"Found: {len(tfFromAidNodes)} nodes\")\n",
    "\n",
    "for (edge, edgeData) in sorted(tfFromAidEdges.items()):\n",
    "    print(f\"Found edge {edge} with {len(edgeData)} starting nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d913a-d003-4b29-a7ef-937ba2ea3428",
   "metadata": {},
   "source": [
    "We check whether the edge data found in the annotations is equivalent with the edge data in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba65b8-531e-489e-a898-faabd0c8578d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allGood = True\n",
    "\n",
    "for edge in set(Eall()) | set(tfFromAidEdges):\n",
    "    if edge == \"oslots\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Checking edge {edge}\")\n",
    "\n",
    "    good = True\n",
    "\n",
    "    if edge not in set(Eall()):\n",
    "        print(\"\\tmissing in TF data\")\n",
    "        good = False\n",
    "\n",
    "    if edge not in tfFromAidEdges:\n",
    "        print(\"\\tmissing in annotation data\")\n",
    "        good = False\n",
    "\n",
    "    if not good:\n",
    "        continue\n",
    "\n",
    "    dataTF = dict(Es(edge).items())\n",
    "    dataAid = tfFromAidEdges[edge]\n",
    "\n",
    "    fromNodesTF = set(dataTF)\n",
    "    fromNodesAid = set(dataAid)\n",
    "\n",
    "    nFromTF = len(fromNodesTF)\n",
    "    nFromAid = len(fromNodesAid)\n",
    "\n",
    "    if fromNodesTF == fromNodesAid:\n",
    "        print(f\"\\tsame {nFromTF} fromNodes\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\tfrom nodes differ: {len(fromNodesTF)} in TF, {len(fromNodesAid)} in Aid\"\n",
    "        )\n",
    "        good = False\n",
    "\n",
    "    diffs = []\n",
    "\n",
    "    nToChecked = 0\n",
    "\n",
    "    for (f, toNodeInfoTF) in dataTF.items():\n",
    "        toNodeInfoAid = dataAid[f]\n",
    "        if type(toNodeInfoTF) is dict:\n",
    "            toNodeInfoTF = {k: str(v) for (k, v) in toNodeInfoTF.items()}\n",
    "        else:\n",
    "            toNodeInfoTF = {x: None for x in toNodeInfoTF}\n",
    "\n",
    "        if toNodeInfoTF != toNodeInfoAid:\n",
    "            diffs.append((f, toNodeInfoTF, toNodeInfoAid))\n",
    "\n",
    "        nToChecked += len(toNodeInfoTF)\n",
    "\n",
    "    if len(diffs):\n",
    "        good = False\n",
    "        print(f\"\\tdifferences in toNodes for {len(diffs)} fromNodes\")\n",
    "\n",
    "        for (f, toNodeInfoTF, toNodeInfoAid) in sorted(diffs)[0:10]:\n",
    "            print(f\"\\t\\tfromNode {f}\")\n",
    "\n",
    "            toNodesTF = set(toNodeInfoTF)\n",
    "            toNodesAid = set(toNodeInfoAid)\n",
    "\n",
    "            nToTF = len(toNodesTF)\n",
    "            nToAid = len(toNodesAid)\n",
    "\n",
    "            if toNodesTF == toNodesAid:\n",
    "                print(f\"\\t\\t\\tsame {nToTF} toNodes\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"\\t\\t\\ttoNodes differ: {len(toNodesTF)} in TF, {len(toNodesAid)} in Aid\"\n",
    "                )\n",
    "            for t in toNodesTF | toNodesAid:\n",
    "                doCompare = True\n",
    "                if t not in toNodesTF:\n",
    "                    print(f\"\\t\\t\\t\\ttoNode {t} not in TF\")\n",
    "                    doCompare = False\n",
    "                else:\n",
    "                    valTF = toNodeInfoTF[t]\n",
    "\n",
    "                if t not in toNodesAid:\n",
    "                    print(f\"\\t\\t\\t\\ttoNode {t} not in Aid\")\n",
    "                    doCompare = False\n",
    "                else:\n",
    "                    valAid = toNodeInfoAid[t]\n",
    "\n",
    "                if doCompare:\n",
    "                    if valTF == valAid:\n",
    "                        print(f\"\\t\\t\\t\\ttoNode{t} values agree: {repr(valTF)}\")\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"\\t\\t\\t\\ttoNode{t} values differ: TF: {repr(valTF)} Aid: {repr(valAid)}\"\n",
    "                        )\n",
    "\n",
    "    print(f\"\\t{nToChecked} toNodes checked\")\n",
    "    print(\"\\tOK\" if good else \"\\tWRONG\")\n",
    "    if not good:\n",
    "        allGood = False\n",
    "        \n",
    "print(f\"{'All OK' if allGood else 'some WRONG'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f843753-feb3-4190-8270-eae4b0ae0c3b",
   "metadata": {},
   "source": [
    "# Conclusion and caveat\n",
    "\n",
    "The WATM representation of the corpus is a faithful and complete representation of the TF source and\n",
    "hence of the TEI source.\n",
    "\n",
    "Well, don't take this too literally, probably there are aspects where the different representations\n",
    "differ.\n",
    "\n",
    "I am aware of the following:\n",
    "\n",
    "* The TEI to TF conversion has lost the exact embedding of elements in the following case:\n",
    "  Suppose element A contains the same words as element B. Then the TF data does not know whether A is\n",
    "  a child of B or the other way round.\n",
    "  \n",
    "  This is repairable by adding parenthood edges between nodes when constructing the TF data.\n",
    "  We should then also convert these TF edges to WATM annotations, for which we need\n",
    "  structured targets: if `n` is the parent of `m`, we must make an annotation with\n",
    "  body `\"parent\"` and target `[n, m]`.\n",
    "\n",
    "* The TF to WATM conversion forgets the types of feature values: it does not make a distinction\n",
    "  between the integer `1` and the string `\"1\"`.\n",
    "  \n",
    "  This is repairable by creating annotations with structured bodies like `{\"att\": value}` instead\n",
    "  of strings like `att=value` as we do now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33de015-f483-4a8a-8ca5-34cf5caa6420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985632b1-fc8e-4222-93b0-5358e4909f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
